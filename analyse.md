# Analyse de l'apport de l'IA sur ce projet

L'utilisation du LLM comme co-développeur a transformé la manière d'aborder le codage. Le fait de fractionner la demande en plusieurs étapes a permis d'obtenir un résultat final très riche et détaillé, mais cela a aussi imposé une certaine rigueur : il fallait régulièrement vérifier le code et demander des corrections, car l'IA avait tendance à "oublier" certaines contraintes de l'historique ou à écraser des fonctionnalités précédentes lors des mises à jour.

À l'inverse, l'approche du "Mega Prompt" à l'étape 7 s'est révélée très pratique pour générer une base solide instantanément. Cependant, même avec un prompt très complet, le résultat n'est jamais parfait à 100 % du premier coup et nécessite toujours une relecture humaine pour les ajustements fins. Il est d'ailleurs important de noter que si ce prompt unique a donné un bon résultat, c'est parce qu'il a été traité par des modèles très performants ; un LLM moins puissant aurait probablement échoué à intégrer autant de contraintes simultanément avec autant de précision.

##### **Repo git :** https://github.com/t-chahbi/M1_TP3_lowcode_nocode